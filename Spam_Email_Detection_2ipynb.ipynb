{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive:"
      ],
      "metadata": {
        "id": "bgVHrCwU_ZtU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TO4NSb16ncJe",
        "outputId": "ebbde970-ea48-4385-e64a-257a0d7b7810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Collection - Loading the Data"
      ],
      "metadata": {
        "id": "-TncqQsJAVwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the paths\n",
        "base_dir = '/content/drive/MyDrive/Spam_Email_Detection_2/archive'\n",
        "\n",
        "# List files in each folder\n",
        "easy_ham_dir = os.listdir(os.path.join(base_dir, 'easy_ham'))\n",
        "hard_ham_dir = os.listdir(os.path.join(base_dir, 'hard_ham'))\n",
        "spam_dir = os.listdir(os.path.join(base_dir, 'spam_2'))\n",
        "\n",
        "# Display contents of each folder\n",
        "print(f\"Easy Ham: {len(easy_ham_dir)} files\")\n",
        "print(f\"Hard Ham: {len(hard_ham_dir)} files\")\n",
        "print(f\"Spam: {len(spam_dir)} files\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDqVfD96AXaD",
        "outputId": "35e35b6c-43db-4603-b6e7-5d8efd077e60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Easy Ham: 2 files\n",
            "Hard Ham: 2 files\n",
            "Spam: 2 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the correct paths\n",
        "base_dir = '/content/drive/MyDrive/Spam_Email_Detection_2/archive'\n",
        "easy_ham_path = os.path.join(base_dir, 'easy_ham', 'easy_ham')\n",
        "hard_ham_path = os.path.join(base_dir, 'hard_ham', 'hard_ham')\n",
        "spam_path = os.path.join(base_dir, 'spam_2', 'spam_2')\n",
        "\n",
        "# List files in each folder again\n",
        "easy_ham_dir = os.listdir(easy_ham_path)\n",
        "hard_ham_dir = os.listdir(hard_ham_path)\n",
        "spam_dir = os.listdir(spam_path)\n",
        "\n",
        "# Display contents of each folder\n",
        "print(f\"Easy Ham: {len(easy_ham_dir)} files\")\n",
        "print(f\"Hard Ham: {len(hard_ham_dir)} files\")\n",
        "print(f\"Spam: {len(spam_dir)} files\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYAsjlkHCNpd",
        "outputId": "b594b1f6-fa7c-44f9-c9e3-c8ce58edfc2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Easy Ham: 2551 files\n",
            "Hard Ham: 250 files\n",
            "Spam: 1397 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing\n",
        "\n",
        "Read the email content from all the files in each category (easy ham, hard ham, and spam).\n",
        "\n",
        "Clean the text by removing any HTML tags and unnecessary characters.\n",
        "\n",
        "Tokenize the text for further analysis.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uT27kjDaC7Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to read and clean email files\n",
        "def read_and_clean_email(file_path):\n",
        "    with open(file_path, 'r', encoding='latin-1') as file:\n",
        "        email_content = file.read()\n",
        "        # Remove HTML tags\n",
        "        email_content = re.sub(r'<.*?>', '', email_content)\n",
        "        # Remove non-alphabetic characters\n",
        "        email_content = re.sub(r'[^a-zA-Z\\s]', '', email_content)\n",
        "        return email_content\n",
        "\n",
        "# Load and clean all emails in each category\n",
        "easy_ham_emails = [read_and_clean_email(os.path.join(easy_ham_path, file)) for file in easy_ham_dir[:5]]  # Load first 5 emails for testing\n",
        "hard_ham_emails = [read_and_clean_email(os.path.join(hard_ham_path, file)) for file in hard_ham_dir[:5]]\n",
        "spam_emails = [read_and_clean_email(os.path.join(spam_path, file)) for file in spam_dir[:5]]\n",
        "\n",
        "# Display sample of cleaned emails\n",
        "print(\"Sample Easy Ham Email:\\n\", easy_ham_emails[0][:500])\n",
        "print(\"\\nSample Hard Ham Email:\\n\", hard_ham_emails[0][:500])\n",
        "print(\"\\nSample Spam Email:\\n\", spam_emails[0][:500])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzo1bYL-C84K",
        "outputId": "4bfc841f-5a9f-46a7-f749-9f5a952284c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Easy Ham Email:\n",
            " From rssfeedsjmasonorg  Tue Oct    \n",
            "ReturnPath \n",
            "DeliveredTo yyyylocalhostexamplecom\n",
            "Received from localhost jalapeno \n",
            "\tby jmasonorg Postfix with ESMTP id BEF\n",
            "\tfor  Tue   Oct    IST\n",
            "Received from jalapeno \n",
            "\tby localhost with IMAP fetchmail\n",
            "\tfor jmlocalhost singledrop Tue  Oct    IST\n",
            "Received from dogmaslashnullorg localhost  by\n",
            "    dogmaslashnullorg  with ESMTP id gK for\n",
            "     Tue  Oct   \n",
            "MessageId \n",
            "To yyyyexamplecom\n",
            "From guardian \n",
            "Subject Factories go flat while we dither over the euro\n",
            "Date Tue  \n",
            "\n",
            "Sample Hard Ham Email:\n",
            " ReturnPath \n",
            "Received from abvsfoacmtaCNETCOM abvsfoacmtacnetcom \n",
            "\tby dogmaslashnullorg  with ESMTP id gALeUJ\n",
            "\tfor  Wed  Jul   \n",
            "Received from abvsfoacagent  by abvsfoacmtaCNETCOM PowerMTATM v Wed  Jul    envelopefrom \n",
            "MessageID \n",
            "Date Wed  Jul    PDT\n",
            "From CNET Newscom Investor \n",
            "To qqqqqqqqqqzdnetexamplecom\n",
            "Subject NEWSCOM INVESTOR Tech stocks drop again on Qwest criminal probe news\n",
            "MimeVersion \n",
            "ContentType texthtml charsetISO\n",
            "ContentTransferEncoding bit\n",
            "XMailer Accucast httpwwwaccucastcom\n",
            "XMailerV\n",
            "\n",
            "Sample Spam Email:\n",
            " From jhaneeujkjdoijaolcom  Mon Jun   \n",
            "ReturnPath jhaneeujkjdoijaolcom\n",
            "DeliveryDate Tue May   \n",
            "Received from   by dogmaslashnullorg\n",
            "     with SMTP id gLBANe for \n",
            "    Tue  May   \n",
            "MessageId \n",
            "From Jane Thurman \n",
            "To webmasterefiie\n",
            "Subject Email  Fax Directory   million email addresses\n",
            "Sender Jane Thurman \n",
            "MIMEVersion \n",
            "ContentType textplain charsetiso\n",
            "Date Tue  May   \n",
            "XKeywords \n",
            "\n",
            "FUTURE TECH INTERNATIONAL\n",
            "\n",
            "SPECIAL OFFER that BLOWS AWAY TRADITIONAL MARKETING  Advertising Age\n",
            "\n",
            "The most powerful fully exp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering\n",
        "\n",
        "We will use TF-IDF (Term Frequency-Inverse Document Frequency) to transform the email text into numerical features."
      ],
      "metadata": {
        "id": "7whukk-qGD3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Combine all emails for TF-IDF\n",
        "all_emails = easy_ham_emails + hard_ham_emails + spam_emails\n",
        "labels = [0] * len(easy_ham_emails) + [0] * len(hard_ham_emails) + [1] * len(spam_emails)  # 0 = ham, 1 = spam\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=3000)  # Limiting features to 3000 for efficiency\n",
        "\n",
        "# Fit and transform the email text to TF-IDF features\n",
        "X = vectorizer.fit_transform(all_emails)\n",
        "\n",
        "# Display the shape of the feature matrix\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85ekUg65GFFj",
        "outputId": "3f951cbd-85cc-497c-96dd-b110431d5724"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature matrix shape: (15, 2881)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building\n",
        "\n",
        "Now, we can move on to training classifiers for spam detection. A good starting point is the Naive Bayes classifier, as it is effective for text classification tasks like spam detection."
      ],
      "metadata": {
        "id": "PFHqrOkXGozr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BFrOR4WmHVGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBDBabu3GrCC",
        "outputId": "b9a23382-92d1-4ddb-95c4-c677db734e56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[2 0]\n",
            " [1 0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80         2\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.33      0.50      0.40         3\n",
            "weighted avg       0.44      0.67      0.53         3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the model did not perform well on the test set, as indicated by the confusion matrix and classification report.\n",
        "\n",
        "Classification Report Interpretation:\n",
        "\n",
        "Precision for class 1 (spam) is 0.00 because there were no true positive predictions.\n",
        "\n",
        "Recall for class 1 (spam) is also 0.00, indicating that the model did not capture any spam emails.\n",
        "\n",
        "The model has a moderate accuracy of 67%, but this is misleading due to the imbalanced nature of the dataset and the fact that it did not predict any spam emails.\n",
        "\n",
        "Possible Reasons for Poor Performance:\n",
        "\n",
        "Imbalance in Classes: The dataset may have an imbalance between the classes (ham vs. spam). With only one spam sample in the test set, the model couldn't learn to recognize spam effectively.\n",
        "\n",
        "Feature Selection: TF-IDF might not capture all relevant features effectively with the small number of samples.\n",
        "\n",
        "Next step:\n",
        "Adjust the Train-Test Split: we will try using a different split to ensure the test set contains more diverse samples of both ham and spam.\n",
        "\n",
        "\n",
        "Try Other Models: You can also try other classifiers, such as Support Vector Machines (SVM) or Logistic Regression, to see if they perform better with the current dataset.\n"
      ],
      "metadata": {
        "id": "m7O_pvBAIwLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets (80% train, 20% test) with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "\n",
        "# Train the model again and evaluate\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model again\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBXT8KCbIOC8",
        "outputId": "27bcfa8d-f34a-4a46-bae6-ba71ba637583"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[2 0]\n",
            " [1 0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80         2\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.33      0.50      0.40         3\n",
            "weighted avg       0.44      0.67      0.53         3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the train-test split with stratification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test) with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "\n",
        "# Initialize the Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NeC_p-BIdLE",
        "outputId": "8457278f-2e98-4f0f-f21d-fd6c1785bc4b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[2 0]\n",
            " [1 0]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80         2\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.33      0.50      0.40         3\n",
            "weighted avg       0.44      0.67      0.53         3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machine (SVM)"
      ],
      "metadata": {
        "id": "H1qNDLGdMS70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "svm_model = SVC(kernel='linear')  # Linear kernel is often a good choice for text data\n",
        "\n",
        "# Train the SVM model\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "svm_y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the SVM model\n",
        "print(\"SVM Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, svm_y_pred))\n",
        "print(\"\\nSVM Classification Report:\")\n",
        "print(classification_report(y_test, svm_y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkorejcnJcI7",
        "outputId": "595308c1-ca59-4c50-b394-704ade0c58d4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Confusion Matrix:\n",
            "[[2 0]\n",
            " [0 1]]\n",
            "\n",
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         3\n",
            "   macro avg       1.00      1.00      1.00         3\n",
            "weighted avg       1.00      1.00      1.00         3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "still poor"
      ],
      "metadata": {
        "id": "rzSEO24MMaFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "MEm8V_xDMdmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize the Logistic Regression classifier\n",
        "log_reg_model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the Logistic Regression model\n",
        "log_reg_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "log_reg_y_pred = log_reg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Logistic Regression model\n",
        "print(\"Logistic Regression Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, log_reg_y_pred))\n",
        "print(\"\\nLogistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, log_reg_y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WKRZ70UJf9r",
        "outputId": "181af054-c680-476a-c338-cfe5ce18a59d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Confusion Matrix:\n",
            "[[2 0]\n",
            " [1 0]]\n",
            "\n",
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      1.00      0.80         2\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.33      0.50      0.40         3\n",
            "weighted avg       0.44      0.67      0.53         3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll focus on handling the class imbalance and adjusting the train-test split. As the confusion metrics are still poor.\n",
        "\n",
        "\n",
        "Step 1: Use Stratified Sampling for Train-Test Split\n",
        "This ensures each class is proportionally represented in both training and testing datasets.\n",
        "\n",
        "Step 2: Handle Class Imbalance\n",
        "We can use resampling techniques to balance the dataset.\n",
        "\n",
        "We'll use the imblearn library for this purpose."
      ],
      "metadata": {
        "id": "nBaJXRiEMxRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w9YgAvuKIkj",
        "outputId": "1e344a97-8946-4588-b9f1-dcb32ab5ced2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "# Define the paths to email datasets\n",
        "easy_ham_path = '/content/drive/MyDrive/Spam_Email_Detection_2/archive/easy_ham/easy_ham'\n",
        "hard_ham_path = '/content/drive/MyDrive/Spam_Email_Detection_2/archive/hard_ham/hard_ham'\n",
        "spam_path = '/content/drive/MyDrive/Spam_Email_Detection_2/archive/spam_2/spam_2'\n",
        "\n",
        "# Function to load emails from a directory\n",
        "def load_emails_from_folder(folder, label):\n",
        "    emails = []\n",
        "    for filename in os.listdir(folder):\n",
        "        with open(os.path.join(folder, filename), 'r', errors='ignore') as file:\n",
        "            emails.append((file.read(), label))\n",
        "    return emails\n",
        "\n",
        "# Load the datasets\n",
        "easy_ham_emails = load_emails_from_folder(easy_ham_path, 'easy_ham')\n",
        "hard_ham_emails = load_emails_from_folder(hard_ham_path, 'hard_ham')\n",
        "spam_emails = load_emails_from_folder(spam_path, 'spam')\n",
        "\n",
        "# Combine all emails into a single DataFrame\n",
        "all_emails = easy_ham_emails + hard_ham_emails + spam_emails\n",
        "data = pd.DataFrame(all_emails, columns=['text', 'label'])\n",
        "\n",
        "# Prepare your features (X) and labels (y)\n",
        "X = data['text']\n",
        "y = data['label']\n",
        "\n",
        "# Vectorize the text data using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_vectorized = vectorizer.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test) with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Handle class imbalance using oversampling for minority classes\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "# Initialize the Naive Bayes classifier\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Train the model on the resampled data\n",
        "model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rf1Rf53AKkkL",
        "outputId": "3c4b87aa-2cde-482c-8a26-44f906c29275"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[507   2   1]\n",
            " [  1  47   2]\n",
            " [  8  10 262]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    easy_ham       0.98      0.99      0.99       510\n",
            "    hard_ham       0.80      0.94      0.86        50\n",
            "        spam       0.99      0.94      0.96       280\n",
            "\n",
            "    accuracy                           0.97       840\n",
            "   macro avg       0.92      0.96      0.94       840\n",
            "weighted avg       0.97      0.97      0.97       840\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally! Phew!"
      ],
      "metadata": {
        "id": "OC8Saoh3NFwE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "High Overall Accuracy: The model achieved an overall accuracy of 97%, which indicates that it is performing very well in classifying the emails.\n",
        "\n",
        "\n",
        "Precision, Recall, and F1-Score:\n",
        "\n",
        "\n",
        "Easy Ham:\n",
        "\n",
        "Precision: 0.98 – Very few false positives, meaning most emails predicted as easy ham are indeed easy ham.\n",
        "\n",
        "Recall: 0.99 – Very few easy ham emails are misclassified as spam or hard ham.\n",
        "\n",
        "F1-Score: 0.99 – A good balance between precision and recall.\n",
        "\n",
        "Hard Ham:\n",
        "Precision: 0.80 – There are some false positives (2 emails predicted as hard ham that are not).\n",
        "\n",
        "Recall: 0.94 – The model identifies 94% of actual hard ham emails correctly, with only 1 false negative.\n",
        "\n",
        "F1-Score: 0.86 – Reasonable, but there's room for improvement.\n",
        "\n",
        "Spam:\n",
        "Precision: 0.99 – Very few false positives, indicating strong performance.\n",
        "\n",
        "Recall: 0.94 – Good at identifying spam, though there are some misclassifications.\n",
        "\n",
        "F1-Score: 0.96 – Overall very strong.\n",
        "Macro and Weighted Averages:\n",
        "\n",
        "The macro average reflects the average of precision, recall, and F1-score across classes, treating all classes equally.\n",
        "\n",
        "The weighted average accounts for the support (number of true instances) of each class, giving a more accurate measure of performance when classes are imbalanced."
      ],
      "metadata": {
        "id": "xA4Q05RYNyKN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment with Different Classifiers\n",
        "We will like to experiment with different Classifiers"
      ],
      "metadata": {
        "id": "_cO21O-7OPqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the classifiers to try\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'SVM': SVC(random_state=42)\n",
        "}\n",
        "\n",
        "# Dictionary to store the results\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    # Create a pipeline with TF-IDF and the classifier\n",
        "    pipeline = make_pipeline(TfidfVectorizer(), clf)\n",
        "\n",
        "    # Split the data into training and testing sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'],\n",
        "                                                        test_size=0.2, random_state=42, stratify=data['label'])\n",
        "\n",
        "    # Fit the model\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Store results\n",
        "    results[name] = {\n",
        "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
        "        'classification_report': classification_report(y_test, y_pred, output_dict=True)\n",
        "    }\n",
        "\n",
        "# Print the results\n",
        "for name, result in results.items():\n",
        "    print(f\"Classifier: {name}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(result['confusion_matrix'])\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(result['classification_report'])\n",
        "    print(\"=\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro3Cc7d9NKvj",
        "outputId": "e1f9d619-6afe-4515-e514-c0fa56af80c1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: Random Forest\n",
            "Confusion Matrix:\n",
            "[[506   1   3]\n",
            " [  2  39   9]\n",
            " [  2   0 278]]\n",
            "\n",
            "Classification Report:\n",
            "{'easy_ham': {'precision': 0.9921568627450981, 'recall': 0.9921568627450981, 'f1-score': 0.9921568627450981, 'support': 510.0}, 'hard_ham': {'precision': 0.975, 'recall': 0.78, 'f1-score': 0.8666666666666667, 'support': 50.0}, 'spam': {'precision': 0.9586206896551724, 'recall': 0.9928571428571429, 'f1-score': 0.9754385964912281, 'support': 280.0}, 'accuracy': 0.9797619047619047, 'macro avg': {'precision': 0.9752591841334235, 'recall': 0.9216713352007471, 'f1-score': 0.9447540419676642, 'support': 840.0}, 'weighted avg': {'precision': 0.9799568965517241, 'recall': 0.9797619047619047, 'f1-score': 0.9791144527986634, 'support': 840.0}}\n",
            "==================================================\n",
            "Classifier: SVM\n",
            "Confusion Matrix:\n",
            "[[509   1   0]\n",
            " [  3  38   9]\n",
            " [  2   0 278]]\n",
            "\n",
            "Classification Report:\n",
            "{'easy_ham': {'precision': 0.9902723735408561, 'recall': 0.9980392156862745, 'f1-score': 0.994140625, 'support': 510.0}, 'hard_ham': {'precision': 0.9743589743589743, 'recall': 0.76, 'f1-score': 0.8539325842696629, 'support': 50.0}, 'spam': {'precision': 0.9686411149825784, 'recall': 0.9928571428571429, 'f1-score': 0.9805996472663139, 'support': 280.0}, 'accuracy': 0.9821428571428571, 'macro avg': {'precision': 0.9777574876274696, 'recall': 0.9169654528478057, 'f1-score': 0.9428909521786588, 'support': 840.0}, 'weighted avg': {'precision': 0.9821147278796516, 'recall': 0.9821428571428571, 'f1-score': 0.9812812490452988, 'support': 840.0}}\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both classifiers—Random Forest and SVM—performed well, with SVM achieving slightly better accuracy and precision metrics overall. Here’s a quick comparison of their performance:\n",
        "\n",
        "\n",
        "Random Forest Results:\n",
        "\n",
        "Accuracy: 97.98%\n",
        "\n",
        "Precision (Macro Average): 97.53%\n",
        "\n",
        "Recall (Macro Average): 92.17%\n",
        "\n",
        "F1-Score (Macro Average): 94.48%\n",
        "\n",
        "SVM Results:\n",
        "\n",
        "Accuracy: 98.21%\n",
        "\n",
        "Precision (Macro Average): 97.78%\n",
        "\n",
        "Recall (Macro Average): 91.70%\n",
        "\n",
        "F1-Score (Macro Average): 94.29%\n",
        "\n",
        "Key Takeaways:\n",
        "\n",
        "Random Forest had a slight edge in classifying easy ham emails but struggled a bit more with hard ham emails.\n",
        "\n",
        "SVM performed consistently across all categories, achieving high precision and recall."
      ],
      "metadata": {
        "id": "dHgsLdIrPQzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since SVM performed slightly better, we will choose it as the primary model for our spam detection.\n",
        "\n",
        "We will be saving the work now"
      ],
      "metadata": {
        "id": "BH79TpWIPoc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Define the classifiers to try\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'SVM': SVC(random_state=42)\n",
        "}\n",
        "\n",
        "# Dictionary to store the results\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    # Create a pipeline with TF-IDF and the classifier\n",
        "    pipeline = make_pipeline(TfidfVectorizer(), clf)\n",
        "\n",
        "    # Split the data into training and testing sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'],\n",
        "                                                        test_size=0.2, random_state=42, stratify=data['label'])\n",
        "\n",
        "    # Fit the model\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    # Store results\n",
        "    results[name] = {\n",
        "        'confusion_matrix': confusion_matrix(y_test, y_pred),\n",
        "        'classification_report': classification_report(y_test, y_pred, output_dict=True)\n",
        "    }\n",
        "\n",
        "    # Save the trained model\n",
        "    joblib.dump(pipeline, f'{name.lower().replace(\" \", \"_\")}_model.pkl')  # Save pipeline\n",
        "\n",
        "# Print the results\n",
        "for name, result in results.items():\n",
        "    print(f\"Classifier: {name}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(result['confusion_matrix'])\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(result['classification_report'])\n",
        "    print(\"=\"*50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ1JqAybRgEN",
        "outputId": "7c24f76a-2672-4d8e-efc7-51c79668785c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: Random Forest\n",
            "Confusion Matrix:\n",
            "[[506   1   3]\n",
            " [  2  39   9]\n",
            " [  2   0 278]]\n",
            "\n",
            "Classification Report:\n",
            "{'easy_ham': {'precision': 0.9921568627450981, 'recall': 0.9921568627450981, 'f1-score': 0.9921568627450981, 'support': 510.0}, 'hard_ham': {'precision': 0.975, 'recall': 0.78, 'f1-score': 0.8666666666666667, 'support': 50.0}, 'spam': {'precision': 0.9586206896551724, 'recall': 0.9928571428571429, 'f1-score': 0.9754385964912281, 'support': 280.0}, 'accuracy': 0.9797619047619047, 'macro avg': {'precision': 0.9752591841334235, 'recall': 0.9216713352007471, 'f1-score': 0.9447540419676642, 'support': 840.0}, 'weighted avg': {'precision': 0.9799568965517241, 'recall': 0.9797619047619047, 'f1-score': 0.9791144527986634, 'support': 840.0}}\n",
            "==================================================\n",
            "Classifier: SVM\n",
            "Confusion Matrix:\n",
            "[[509   1   0]\n",
            " [  3  38   9]\n",
            " [  2   0 278]]\n",
            "\n",
            "Classification Report:\n",
            "{'easy_ham': {'precision': 0.9902723735408561, 'recall': 0.9980392156862745, 'f1-score': 0.994140625, 'support': 510.0}, 'hard_ham': {'precision': 0.9743589743589743, 'recall': 0.76, 'f1-score': 0.8539325842696629, 'support': 50.0}, 'spam': {'precision': 0.9686411149825784, 'recall': 0.9928571428571429, 'f1-score': 0.9805996472663139, 'support': 280.0}, 'accuracy': 0.9821428571428571, 'macro avg': {'precision': 0.9777574876274696, 'recall': 0.9169654528478057, 'f1-score': 0.9428909521786588, 'support': 840.0}, 'weighted avg': {'precision': 0.9821147278796516, 'recall': 0.9821428571428571, 'f1-score': 0.9812812490452988, 'support': 840.0}}\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}